{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ca335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda366d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (83484, 28, 28)\n",
      "y_train (83484,)\n",
      "X_test (0,)\n",
      "y_test (0,)\n"
     ]
    }
   ],
   "source": [
    "# root_dir = \"/content/drive/MyDrive/Colab Notebook Files/OCT2017\"\n",
    "root_dir = r\"C:\\Users\\User\\Downloads\\archive\\OCT2017\"\n",
    "out_dir = r\"D:\\dataset\"\n",
    "\n",
    "data = np.load(out_dir + \"/thesis-dataset.npz\")\n",
    "for k, v in data.items():\n",
    "    print(k, data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10464c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.get(\"X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7e92b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83484, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9493f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def load_data(self):\n",
    "        real_data = X_train\n",
    "        real_data = real_data[:2000].astype('float32')\n",
    "        real_data = np.expand_dims(real_data, axis=3) / 255\n",
    "\n",
    "        self.real_data = real_data\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.real_data = None\n",
    "        self.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d190093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 7, 7, 64)          51264     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 7, 7, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 4, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 2, 2, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 2, 2, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " lambda_8 (Lambda)           (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,079,425\n",
      "Trainable params: 1,078,465\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class C(object):\n",
    "    @staticmethod\n",
    "    def random_layer(last_output, filter_size):\n",
    "        layer = np.random.choice([layers.Conv2D, layers.DepthwiseConv2D, layers.Conv2DTranspose],\n",
    "                                 p=[0.20, 0.20, 0.60])\n",
    "\n",
    "        hyper_parameters = {\n",
    "            'filters': filter_size,\n",
    "            'kernel_size': (lambda x: [x, x])(np.random.randint(1, 4)),\n",
    "            'strides': (lambda x: [x, x])(np.random.randint(1, 4)),\n",
    "            'padding': 'valid',\n",
    "            'dilation_rate': (lambda x: [x, x])(np.random.randint(1, 4)),\n",
    "            'activation': np.random.choice(['relu']),\n",
    "        }\n",
    "\n",
    "        if layer == layers.Conv2D:\n",
    "            hyper_parameters[np.random.choice(['dilation_rate'])] = [1, 1]\n",
    "            hyper_parameters['padding'] = 'same'\n",
    "\n",
    "        elif layer == layers.DepthwiseConv2D:\n",
    "            hyper_parameters[np.random.choice(['dilation_rate'])] = [1, 1]\n",
    "            hyper_parameters['padding'] = 'same'\n",
    "            hyper_parameters.pop('filters')\n",
    "\n",
    "        elif layer == layers.Conv2DTranspose:\n",
    "            if last_output.shape[1] > C.image_width:\n",
    "                hyper_parameters['strides'] = [1, 1]\n",
    "            else:\n",
    "                hyper_parameters['strides'] = [2, 2]\n",
    "                hyper_parameters['dilation_rate'] = [1, 1]\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                layer = layer(**hyper_parameters)(last_output)\n",
    "                break\n",
    "            except ValueError:\n",
    "                last_output = layers.ZeroPadding2D(data_format='channels_last')(last_output)\n",
    "\n",
    "        layer = layers.BatchNormalization()(layer)\n",
    "        return layer\n",
    "\n",
    "    @staticmethod\n",
    "    def make_fixed_discriminator():\n",
    "        model_input = layers.Input(shape=[C.image_width, C.image_width, 1]) \n",
    "        model_output = model_input\n",
    "        for i in range(4):\n",
    "            model_output = layers.Conv2D(filters=(2 ** i) * 32,\n",
    "                                           kernel_size=[5, 5],\n",
    "                                           strides=[2, 2],\n",
    "                                           padding='same',\n",
    "                                           )(model_output)\n",
    "            model_output = layers.BatchNormalization()(model_output)\n",
    "            model_output = layers.LeakyReLU()(model_output)\n",
    "\n",
    "        model_output = layers.Lambda(lambda x: x * 2)(model_output)\n",
    "\n",
    "        model_output = layers.Flatten()(model_output)\n",
    "        model_output = layers.Dense(units=1, activation='linear')(model_output)\n",
    "\n",
    "        model = keras.Model(inputs=model_input, outputs=model_output, name='discriminator')\n",
    "\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def make_random_discriminator():\n",
    "        model_input = layers.Input(shape=[C.image_width, C.image_width, 1])\n",
    "        model_output = model_input\n",
    "        for i in range(C.discriminator_layer_size()):\n",
    "            model_output = layers.Conv2D(filters=(2 ** i) * 32,\n",
    "                                           kernel_size=[5, 5],\n",
    "                                           strides=[2, 2],\n",
    "                                           padding='same',\n",
    "                                           )(model_output)\n",
    "            model_output = layers.BatchNormalization()(model_output)\n",
    "            model_output = layers.LeakyReLU()(model_output)\n",
    "\n",
    "        model_output = layers.Lambda(lambda x: x * 2)(model_output)\n",
    "\n",
    "        model_output = layers.Flatten()(model_output)\n",
    "        model_output = layers.Dense(units=1, activation='linear')(model_output)\n",
    "\n",
    "        model = keras.Model(inputs=model_input, outputs=model_output, name='discriminator')\n",
    "\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def make_fixed_generator():\n",
    "        model_output = layers.Input(shape=[C.noise_dimension])\n",
    "        model_input = model_output\n",
    "        model_output = layers.Dense(units=7 * 7 * 128)(model_output)\n",
    "        model_output = layers.Reshape([7, 7, 128])(model_output)\n",
    "        model_output = layers.Conv2DTranspose(filters=64,\n",
    "                                                kernel_size=[5, 5],\n",
    "                                                strides=[2, 2],\n",
    "                                                padding='same',\n",
    "                                                activation='relu'\n",
    "                                                )(model_output)\n",
    "        model_output = layers.BatchNormalization()(model_output)\n",
    "        model_output = layers.Conv2DTranspose(filters=32,\n",
    "                                                kernel_size=[5, 5],\n",
    "                                                strides=[2, 2],\n",
    "                                                padding='same',\n",
    "                                                activation='relu'\n",
    "                                                )(model_output)\n",
    "        model_output = layers.BatchNormalization()(model_output)\n",
    "        model_output = layers.Conv2DTranspose(filters=1,\n",
    "                                                kernel_size=[5, 5],\n",
    "                                                strides=[1, 1],\n",
    "                                                padding='same',\n",
    "                                                activation='tanh'\n",
    "                                                )(model_output)\n",
    "        model_output = layers.Lambda(lambda x: (x + 1) / 2)(model_output)\n",
    "\n",
    "        return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_random_generator():\n",
    "        model_input = layers.Input(shape=[C.noise_dimension])\n",
    "        model_output =model_input\n",
    "        model_output = layers.Dense(C.first_convolution_shape[0]\n",
    "                                      * C.first_convolution_shape[1]\n",
    "                                      * C.first_convolution_shape[2])(model_output)\n",
    "        model_output = layers.Reshape(C.first_convolution_shape)(model_output)\n",
    "\n",
    "        for i in reversed(range(C.generator_layer_size())):\n",
    "            model_output = C.random_layer(model_output, 2 ** (i + 2))\n",
    "\n",
    "        output_difference = keras.Model(inputs=model_input, outputs=model_output).output_shape[1] - C.image_width\n",
    "        if output_difference >= 0:\n",
    "            model_output = layers.Conv2D(\n",
    "                filters=1,\n",
    "                kernel_size=[output_difference + 1, output_difference + 1],\n",
    "                activation='tanh',\n",
    "            )(model_output)\n",
    "        else:\n",
    "            model_output = layers.Conv2DTranspose(\n",
    "                filters=1,\n",
    "                kernel_size=[-output_difference + 1, -output_difference + 1],\n",
    "                activation='tanh',\n",
    "            )(model_output)\n",
    "\n",
    "        model_output = layers.Lambda(lambda x: (x + 1) / 2)(model_output)\n",
    "\n",
    "        model = keras.Model(inputs=model_input, outputs=model_output, name='generator')\n",
    "\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def generator_layer_size():\n",
    "        return np.random.randint(6, 8)\n",
    "\n",
    "    @staticmethod\n",
    "    def discriminator_layer_size():\n",
    "        return np.random.randint(3, 5)\n",
    "\n",
    "    image_width = 28\n",
    "    noise_dimension = 128\n",
    "    first_convolution_shape = np.array([4, 4, 128])\n",
    "    gan_size = 3\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.003\n",
    "\n",
    "    path = r'D:\\results'\n",
    "    generate_image_size = 10\n",
    "    \n",
    "    \n",
    "# fixed_generator_model = C.make_fixed_generator()\n",
    "# fixed_generator_model.summary()\n",
    "\n",
    "fixed_discriminator_model = C.make_fixed_discriminator()\n",
    "fixed_discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4850da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6272)              809088    \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 14, 14, 64)       204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_15 (Conv2D  (None, 28, 28, 32)       51232     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_16 (Conv2D  (None, 28, 28, 1)        801       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " lambda_9 (Lambda)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,066,369\n",
      "Trainable params: 1,066,177\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fixed_generator_model = C.make_fixed_generator()\n",
    "fixed_generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4674db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 64)          51264     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 7, 7, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 4, 4, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " lambda_10 (Lambda)          (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259,969\n",
      "Trainable params: 259,521\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_discriminator_model = C.make_random_discriminator()\n",
    "random_discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b5abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2048)              264192    \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_17 (Conv2D  (None, 8, 8, 256)        33024     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 8, 8, 256)        512       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2D  (None, 16, 16, 64)       16448     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_1 (Depthwi  (None, 16, 16, 64)       128       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 16, 16, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_2 (Depthwi  (None, 8, 8, 64)         128       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " depthwise_conv2d_3 (Depthwi  (None, 4, 4, 64)         640       \n",
      " seConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 4, 4, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2D  (None, 8, 8, 4)          260       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 8, 8, 4)          16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 28, 28, 1)        1765      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " lambda_11 (Lambda)          (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,185\n",
      "Trainable params: 318,641\n",
      "Non-trainable params: 1,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_generator_model = C.make_random_generator()\n",
    "random_generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76100bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan(object):\n",
    "    def __init__(self, real_data, generator, discriminator, learning_rate):\n",
    "        self.real_data = real_data\n",
    "        optimizer = keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "        discriminator.trainable = True\n",
    "        discriminator.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        discriminator.trainable = False\n",
    "        adversarial = keras.Model(inputs=generator.input, outputs=discriminator(generator.output))\n",
    "        adversarial.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.adversarial = adversarial\n",
    "\n",
    "    def train_on_batch_index(self, batch_index):\n",
    "        noise = np.random.uniform(-1, 1, [len(batch_index), C.noise_dimension]).astype('float32')\n",
    "        fake_data = self.generator.predict(noise)\n",
    "        real_data = self.real_data[batch_index]\n",
    "\n",
    "        self.adversarial.train_on_batch(noise, np.ones([len(batch_index), 1]))\n",
    "        self.discriminator.train_on_batch(real_data, np.ones([len(batch_index), 1]))\n",
    "        self.discriminator.train_on_batch(fake_data, np.zeros([len(batch_index), 1]))\n",
    "\n",
    "    def get_generator_weights(self):\n",
    "        return self.generator.get_weights()\n",
    "\n",
    "    def set_generator_weights(self, weights):\n",
    "        self.generator.set_weights(weights)\n",
    "\n",
    "    def get_discriminator_weights(self):\n",
    "        return self.discriminator.get_weights()\n",
    "\n",
    "    def set_discriminator_weights(self, weights):\n",
    "        self.discriminator.set_weights(weights)\n",
    "\n",
    "    def get_sample_images(self):\n",
    "        noise = np.random.uniform(-1, 1, [C.generate_image_size, C.noise_dimension])\n",
    "        image_arrays = self.generator.predict(x=noise) * 255.0\n",
    "\n",
    "        return image_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d9ccd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributedGan(object):\n",
    "    def __init__(self, distribution_size, real_data, generator, discriminator):\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.gans = [Gan(real_data[np.random.choice(len(real_data), len(real_data))],\n",
    "                         keras.models.clone_model(generator),\n",
    "                         keras.models.clone_model(discriminator),\n",
    "                         C.learning_rate * distribution_size) for _ in range(distribution_size)]\n",
    "\n",
    "    def get_generator_weights(self):\n",
    "        weights_set = [gan.get_generator_weights() for gan in self.gans]\n",
    "        return np.mean(weights_set, axis=0)\n",
    "\n",
    "    def set_generator_weights(self, weights):\n",
    "        self.generator.set_weights(weights)\n",
    "        [gan.set_generator_weights(weights) for gan in self.gans]\n",
    "\n",
    "    def get_discriminator_weights(self):\n",
    "        weights_set = ([gan.get_discriminator_weights() for gan in self.gans])\n",
    "        return np.mean(weights_set, axis=0)\n",
    "\n",
    "    def set_discriminator_weights(self, weights):\n",
    "        self.discriminator.set_weights(weights)\n",
    "        [gan.set_discriminator_weights(weights) for gan in self.gans]\n",
    "\n",
    "    def train_on_batch_index(self, batch_index):\n",
    "        [gan.train_on_batch_index(batch_index) for gan in self.gans]\n",
    "        self.set_generator_weights(self.get_generator_weights())\n",
    "        self.set_discriminator_weights(self.get_discriminator_weights())\n",
    "\n",
    "    def save_generator(self, directory_path, iteration_number):\n",
    "        generator_path = directory_path + '/generator'\n",
    "        try:\n",
    "            os.makedirs(generator_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        self.generator.save_weights(generator_path + '/weights.h5')\n",
    "        with open(generator_path + '/architecture.json', 'w') as f:\n",
    "            f.write(self.generator.to_json())\n",
    "        keras.utils.plot_model(self.generator, generator_path + '/graph.png', show_shapes=True)\n",
    "\n",
    "        image_path = directory_path + '/image'\n",
    "\n",
    "        image_arrays = self.gans[0].get_sample_images()\n",
    "\n",
    "        try:\n",
    "            os.makedirs(image_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        for i in range(len(image_arrays)):\n",
    "            image.save_img(x=image_arrays[i],\n",
    "                           path=image_path + '/iteration%d num%d.png' % (iteration_number, i))\n",
    "\n",
    "    def save_discriminator(self, directory_path):\n",
    "        discriminator_path = directory_path + '/discriminator'\n",
    "        try:\n",
    "            os.makedirs(discriminator_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        self.discriminator.save_weights(discriminator_path + '/weights.h5')\n",
    "        with open(discriminator_path + '/architecture.json', 'w') as f:\n",
    "            f.write(self.discriminator.to_json())\n",
    "        keras.utils.plot_model(self.discriminator, discriminator_path + '/graph.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c34e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDistributedGan(object):\n",
    "    def __init__(self, real_data, distribution_size, generators, discriminators):\n",
    "        self.same_generator_gans_group = [[] for _ in range(len(generators))]\n",
    "        self.same_discriminator_gans_group = [[] for _ in range(len(discriminators))]\n",
    "        self.gans = []\n",
    "\n",
    "        for i in range(len(generators)):\n",
    "            for j in range(len(discriminators)):\n",
    "                distributed_gan = DistributedGan(distribution_size,\n",
    "                                                 real_data[np.random.choice(len(real_data), len(real_data))],\n",
    "                                                 keras.models.clone_model(generators[i]),\n",
    "                                                 keras.models.clone_model(discriminators[j]))\n",
    "\n",
    "                self.gans.append(distributed_gan)\n",
    "                self.same_generator_gans_group[i].append(distributed_gan)\n",
    "                self.same_discriminator_gans_group[j].append(distributed_gan)\n",
    "\n",
    "    def get_generators_weights(self):\n",
    "        generators_weights = []\n",
    "        for same_generator_gans in self.same_generator_gans_group:\n",
    "            weights_set = [gan.get_generator_weights() for gan in same_generator_gans]\n",
    "            generators_weights.append(np.mean(weights_set, axis=0))\n",
    "\n",
    "        return generators_weights\n",
    "\n",
    "    def set_generators_weights(self, generators_weights):\n",
    "        for same_generator_gans, generator_weights in zip(self.same_generator_gans_group, generators_weights):\n",
    "            [gan.set_generator_weights(generator_weights) for gan in same_generator_gans]\n",
    "\n",
    "    def get_discriminators_weights(self):\n",
    "        discriminators_weights = []\n",
    "        for same_discriminator_gans in self.same_discriminator_gans_group:\n",
    "            weights_set = []\n",
    "            for same_discriminator_gan in same_discriminator_gans:\n",
    "                weights_set.append(same_discriminator_gan.get_discriminator_weights())\n",
    "            discriminators_weights.append(np.mean(np.array(weights_set), axis=0))\n",
    "\n",
    "        return discriminators_weights\n",
    "\n",
    "    def set_discriminators_weights(self, discriminators_weights):\n",
    "        for same_discriminator_gans, discriminator_weights\\\n",
    "                in zip(self.same_discriminator_gans_group, discriminators_weights):\n",
    "            [gan.set_discriminator_weights(discriminator_weights) for gan in same_discriminator_gans]\n",
    "\n",
    "    def train_on_batch_index(self, batch_index):\n",
    "        [gan.train_on_batch_index(batch_index) for gan in self.gans]\n",
    "        self.set_generators_weights(self.get_generators_weights())\n",
    "        self.set_discriminators_weights(self.get_discriminators_weights())\n",
    "\n",
    "    def save(self, iteration_number):\n",
    "        for i in range(len(self.same_generator_gans_group)):\n",
    "            distributed_gan = self.same_generator_gans_group[i][0]\n",
    "            distributed_gan.save_generator(C.path + '/generator %d' % i, iteration_number)\n",
    "\n",
    "        for i in range(len(self.same_discriminator_gans_group)):\n",
    "            distributed_gan = self.same_discriminator_gans_group[i][0]\n",
    "            distributed_gan.save_discriminator(C.path + '/discriminator %d' % i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use fixed generator and discriminator for test? [y/n]\n",
      "y\n",
      "generator size :\n",
      "1\n",
      "discriminator size :\n",
      "1\n",
      "distribution size :\n",
      "1\n",
      "iteration size :\n",
      "100\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "iteration 0\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 20ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 19ms/step\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 16ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 17ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 16ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "iteration 10\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 16ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "3/3 [==============================] - 0s 15ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    real_data = Data().real_data\n",
    "    print('use fixed generator and discriminator for test? [y/n]')\n",
    "    if input() == 'y':\n",
    "        make_generator_function = C.make_fixed_generator\n",
    "        make_discriminator_function = C.make_fixed_discriminator\n",
    "    else:\n",
    "        make_generator_function = C.make_random_generator\n",
    "        make_discriminator_function = C.make_random_discriminator\n",
    "\n",
    "    print('generator size :')\n",
    "    generator_size = int(input())\n",
    "\n",
    "    print('discriminator size :')\n",
    "    discriminator_size = int(input())\n",
    "\n",
    "    print('distribution size :')\n",
    "    distribution_size = int(input())\n",
    "\n",
    "    print('iteration size :')\n",
    "    iteration_size = int(input())\n",
    "\n",
    "    generators = [make_generator_function() for _ in range(generator_size)]\n",
    "    discriminators = [make_discriminator_function() for _ in range(discriminator_size)]\n",
    "\n",
    "    multi_distributed_gan = MultiDistributedGan(real_data, distribution_size, generators, discriminators)\n",
    "\n",
    "    for i in range(iteration_size):\n",
    "        if i % 10 == 0:\n",
    "            multi_distributed_gan.save(i)\n",
    "            print('iteration', i)\n",
    "\n",
    "        batch_indexes = np.array_split(np.random.permutation(len(real_data)), int(len(real_data) / C.batch_size))\n",
    "        for batch_index in batch_indexes:\n",
    "            multi_distributed_gan.train_on_batch_index(batch_index)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81103d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
