{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2070 SUPER, compute capability 7.5\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\mixed_precision\\loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "\n",
    "\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:01<00:00, 586.46it/s]\n",
      "100%|██████████| 1050/1050 [00:01<00:00, 886.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = \"D:/extended dataset/Train\"\n",
    "\n",
    "CATEGORIES = [\"yes\", \"no\"]\n",
    "\n",
    "training_data = []\n",
    "\n",
    "IMG_SIZE = 50\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                \n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                print(e)\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "X= X/255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=10, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "    \n",
    "    data = list(zip(image_list, label_list))\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = create_clients(X_train, y_train, num_clients=5, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "co = 0\n",
    "for (client_name, data) in clients.items():\n",
    "    co+=1\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "   \n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_1': <BatchDataset shapes: ((None, 50, 50, 3), (None, 2)), types: (tf.float64, tf.float32)>,\n",
       " 'client_2': <BatchDataset shapes: ((None, 50, 50, 3), (None, 2)), types: (tf.float64, tf.float32)>,\n",
       " 'client_3': <BatchDataset shapes: ((None, 50, 50, 3), (None, 2)), types: (tf.float64, tf.float32)>,\n",
       " 'client_4': <BatchDataset shapes: ((None, 50, 50, 3), (None, 2)), types: (tf.float64, tf.float32)>,\n",
       " 'client_5': <BatchDataset shapes: ((None, 50, 50, 3), (None, 2)), types: (tf.float64, tf.float32)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train)\n",
    "del(y_train)\n",
    "del(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "class SimpleModel:\n",
    "    def build(self):\n",
    "        model = VGG16(include_top=False,input_shape=(50, 50, 3), weights='imagenet')\n",
    "        transfer_layer = model.get_layer('block5_pool')\n",
    "        conv_model = Model(inputs=model.input, outputs=transfer_layer.output)\n",
    "        # Start a new Keras Sequential model.\n",
    "        new_model = Sequential()\n",
    "\n",
    "        # Add the convolutional part of the VGG16 model from above.\n",
    "        new_model.add(conv_model)\n",
    "\n",
    "        # Flatten the output of the VGG16 model because it is from a\n",
    "        # convolutional layer.\n",
    "        new_model.add(Flatten())\n",
    "\n",
    "        # Add a dense (aka. fully-connected) layer.\n",
    "        # This is for combining features that the VGG16 model has\n",
    "        # recognized in the image.\n",
    "\n",
    "        new_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "\n",
    "        # Add the final layer for the actual classification.\n",
    "        new_model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf_gpu_final\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "optimizer = Adam(lr=.00001)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    print(global_count)\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "#l_X =  tf.data.Dataset.from_tensor_slices((list(X)[0:52], list(y_train)[0:52]))\n",
    "#final_lx = l_X.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n\\nscaled_local_weight_list = list()\\nscaling_factor = weight_scalling_factor(clients_batched, clients_batched['client_20'])\\nscaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\\nscaled_local_weight_list.append(scaled_weights)\\nglobal_model.set_weights(average_weights)\\naverage_weights = sum_scaled_weights(scaled_local_weight_list)\\ndel local_model\\nK.clear_session()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smlp_global = SimpleModel()\n",
    "#local_model = smlp_global.build()\n",
    "#local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "#set local model weight to the weight of the global model\n",
    "#local_model.set_weights(global_weights)\n",
    "        \n",
    "#fit local model with client's data\n",
    "#global_weights = global_model.get_weights()\n",
    "#local_model.set_weights(global_weights)\n",
    "\n",
    "#local_model.fit(clients_batched['client_20'], epochs=15, verbose=1)\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "scaled_local_weight_list = list()\n",
    "scaling_factor = weight_scalling_factor(clients_batched, clients_batched['client_20'])\n",
    "scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "scaled_local_weight_list.append(scaled_weights)\n",
    "global_model.set_weights(average_weights)\n",
    "average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "del local_model\n",
    "K.clear_session()\n",
    "\"\"\"\n",
    "#for element in final_lx:\n",
    "#  print(element)\n",
    "#final_lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlp_global = SimpleModel()\n",
    "global_model = smlp_global.build()\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "local_model = smlp_global.build()\n",
    "local_model.compile(optimizer= 'adam', loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 33ms/step - loss: 0.4912 - categorical_accuracy: 0.7487\n",
      "comm_round: 0 | global_acc: 73.810% | global_loss: 0.5679758191108704\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5010 - categorical_accuracy: 0.7751\n",
      "comm_round: 0 | global_acc: 77.143% | global_loss: 0.5683660507202148\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5529 - categorical_accuracy: 0.7328\n",
      "comm_round: 0 | global_acc: 76.667% | global_loss: 0.5753054022789001\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.5412 - categorical_accuracy: 0.7222\n",
      "comm_round: 0 | global_acc: 74.762% | global_loss: 0.5991712808609009\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.4854 - categorical_accuracy: 0.7804\n",
      "comm_round: 0 | global_acc: 65.714% | global_loss: 0.6011168956756592\n",
      "1920\n",
      "comm_round: 0 | global_acc: 75.714% | global_loss: 0.5629990696907043\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4442 - categorical_accuracy: 0.8122\n",
      "comm_round: 1 | global_acc: 80.476% | global_loss: 0.5419005751609802\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5117 - categorical_accuracy: 0.7831\n",
      "comm_round: 1 | global_acc: 70.000% | global_loss: 0.625560462474823\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5268 - categorical_accuracy: 0.7566\n",
      "comm_round: 1 | global_acc: 70.952% | global_loss: 0.612661600112915\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.5025 - categorical_accuracy: 0.7751\n",
      "comm_round: 1 | global_acc: 74.286% | global_loss: 0.5603225231170654\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3947 - categorical_accuracy: 0.8228\n",
      "comm_round: 1 | global_acc: 71.905% | global_loss: 0.5849319100379944\n",
      "1920\n",
      "comm_round: 1 | global_acc: 76.667% | global_loss: 0.5729275345802307\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5263 - categorical_accuracy: 0.7460\n",
      "comm_round: 2 | global_acc: 71.429% | global_loss: 0.601204514503479\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5347 - categorical_accuracy: 0.7778\n",
      "comm_round: 2 | global_acc: 78.571% | global_loss: 0.5639596581459045\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5129 - categorical_accuracy: 0.7910\n",
      "comm_round: 2 | global_acc: 80.000% | global_loss: 0.5528873205184937\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.4657 - categorical_accuracy: 0.7751\n",
      "comm_round: 2 | global_acc: 81.905% | global_loss: 0.5135073065757751\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3663 - categorical_accuracy: 0.8571\n",
      "comm_round: 2 | global_acc: 82.857% | global_loss: 0.49300217628479004\n",
      "1920\n",
      "comm_round: 2 | global_acc: 80.476% | global_loss: 0.5308778285980225\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3962 - categorical_accuracy: 0.8439\n",
      "comm_round: 3 | global_acc: 78.095% | global_loss: 0.5302796363830566\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3717 - categorical_accuracy: 0.8571\n",
      "comm_round: 3 | global_acc: 85.714% | global_loss: 0.4917330741882324\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4380 - categorical_accuracy: 0.8095\n",
      "comm_round: 3 | global_acc: 83.333% | global_loss: 0.5094854235649109\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3861 - categorical_accuracy: 0.8519\n",
      "comm_round: 3 | global_acc: 85.238% | global_loss: 0.46660664677619934\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3218 - categorical_accuracy: 0.8677\n",
      "comm_round: 3 | global_acc: 75.238% | global_loss: 0.5424818992614746\n",
      "1920\n",
      "comm_round: 3 | global_acc: 89.524% | global_loss: 0.4554174840450287\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4971 - categorical_accuracy: 0.7725\n",
      "comm_round: 4 | global_acc: 70.952% | global_loss: 0.6025192737579346\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2407 - categorical_accuracy: 0.9312\n",
      "comm_round: 4 | global_acc: 86.190% | global_loss: 0.47690117359161377\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3460 - categorical_accuracy: 0.8651\n",
      "comm_round: 4 | global_acc: 93.333% | global_loss: 0.427656888961792\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3503 - categorical_accuracy: 0.8624\n",
      "comm_round: 4 | global_acc: 74.286% | global_loss: 0.5519511699676514\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2909 - categorical_accuracy: 0.9101\n",
      "comm_round: 4 | global_acc: 85.238% | global_loss: 0.49110129475593567\n",
      "1920\n",
      "comm_round: 4 | global_acc: 87.143% | global_loss: 0.45820221304893494\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3812 - categorical_accuracy: 0.8333\n",
      "comm_round: 5 | global_acc: 83.333% | global_loss: 0.5300232172012329\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2740 - categorical_accuracy: 0.8862\n",
      "comm_round: 5 | global_acc: 78.571% | global_loss: 0.5299587249755859\n",
      "1920\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.3504 - categorical_accuracy: 0.8704\n",
      "comm_round: 5 | global_acc: 79.048% | global_loss: 0.5096698999404907\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.3818 - categorical_accuracy: 0.8624\n",
      "comm_round: 5 | global_acc: 81.905% | global_loss: 0.5297605395317078\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2693 - categorical_accuracy: 0.9021\n",
      "comm_round: 5 | global_acc: 75.238% | global_loss: 0.5500850677490234\n",
      "1920\n",
      "comm_round: 5 | global_acc: 91.905% | global_loss: 0.4473614990711212\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2867 - categorical_accuracy: 0.8836\n",
      "comm_round: 6 | global_acc: 87.143% | global_loss: 0.45848923921585083\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.1647 - categorical_accuracy: 0.9392\n",
      "comm_round: 6 | global_acc: 86.667% | global_loss: 0.4340716004371643\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3491 - categorical_accuracy: 0.8704\n",
      "comm_round: 6 | global_acc: 86.667% | global_loss: 0.4718770682811737\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.3086 - categorical_accuracy: 0.9180\n",
      "comm_round: 6 | global_acc: 87.143% | global_loss: 0.46918168663978577\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2204 - categorical_accuracy: 0.9339\n",
      "comm_round: 6 | global_acc: 78.095% | global_loss: 0.5184544324874878\n",
      "1920\n",
      "comm_round: 6 | global_acc: 93.333% | global_loss: 0.40778931975364685\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4337 - categorical_accuracy: 0.8333\n",
      "comm_round: 7 | global_acc: 78.095% | global_loss: 0.5467760562896729\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.1316 - categorical_accuracy: 0.9550\n",
      "comm_round: 7 | global_acc: 90.000% | global_loss: 0.4181067943572998\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3283 - categorical_accuracy: 0.8704\n",
      "comm_round: 7 | global_acc: 77.143% | global_loss: 0.5208573937416077\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.2141 - categorical_accuracy: 0.9286\n",
      "comm_round: 7 | global_acc: 76.190% | global_loss: 0.5129548907279968\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1223 - categorical_accuracy: 0.9550\n",
      "comm_round: 7 | global_acc: 91.905% | global_loss: 0.3967684805393219\n",
      "1920\n",
      "comm_round: 7 | global_acc: 88.095% | global_loss: 0.4399624466896057\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2578 - categorical_accuracy: 0.9048\n",
      "comm_round: 8 | global_acc: 83.810% | global_loss: 0.4670882523059845\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.1976 - categorical_accuracy: 0.9312\n",
      "comm_round: 8 | global_acc: 83.810% | global_loss: 0.46458154916763306\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.2077 - categorical_accuracy: 0.9286\n",
      "comm_round: 8 | global_acc: 93.810% | global_loss: 0.3907490670681\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.1637 - categorical_accuracy: 0.9471\n",
      "comm_round: 8 | global_acc: 93.810% | global_loss: 0.37606728076934814\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.1083 - categorical_accuracy: 0.9577\n",
      "comm_round: 8 | global_acc: 91.429% | global_loss: 0.406661719083786\n",
      "1920\n",
      "comm_round: 8 | global_acc: 90.476% | global_loss: 0.4165661334991455\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.2247 - categorical_accuracy: 0.9101\n",
      "comm_round: 9 | global_acc: 87.143% | global_loss: 0.49246668815612793\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.1084 - categorical_accuracy: 0.9656\n",
      "comm_round: 9 | global_acc: 92.381% | global_loss: 0.3913712203502655\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.1262 - categorical_accuracy: 0.9524\n",
      "comm_round: 9 | global_acc: 91.905% | global_loss: 0.40962913632392883\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.1025 - categorical_accuracy: 0.9735\n",
      "comm_round: 9 | global_acc: 83.810% | global_loss: 0.47958114743232727\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0913 - categorical_accuracy: 0.9709\n",
      "comm_round: 9 | global_acc: 90.000% | global_loss: 0.4151088297367096\n",
      "1920\n",
      "comm_round: 9 | global_acc: 98.571% | global_loss: 0.3447987735271454\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.1271 - categorical_accuracy: 0.9603\n",
      "comm_round: 10 | global_acc: 88.095% | global_loss: 0.4541003406047821\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0873 - categorical_accuracy: 0.9683\n",
      "comm_round: 10 | global_acc: 94.762% | global_loss: 0.3696916997432709\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.1242 - categorical_accuracy: 0.9630\n",
      "comm_round: 10 | global_acc: 75.714% | global_loss: 0.5598450303077698\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0769 - categorical_accuracy: 0.9762\n",
      "comm_round: 10 | global_acc: 94.286% | global_loss: 0.3759858310222626\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0645 - categorical_accuracy: 0.9788\n",
      "comm_round: 10 | global_acc: 94.286% | global_loss: 0.38107049465179443\n",
      "1920\n",
      "comm_round: 10 | global_acc: 93.333% | global_loss: 0.3840668201446533\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0524 - categorical_accuracy: 0.9868\n",
      "comm_round: 11 | global_acc: 94.762% | global_loss: 0.368755966424942\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0823 - categorical_accuracy: 0.9735\n",
      "comm_round: 11 | global_acc: 77.143% | global_loss: 0.5115089416503906\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.1984 - categorical_accuracy: 0.9206\n",
      "comm_round: 11 | global_acc: 89.524% | global_loss: 0.42608606815338135\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.1425 - categorical_accuracy: 0.9444\n",
      "comm_round: 11 | global_acc: 90.952% | global_loss: 0.4093713164329529\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0742 - categorical_accuracy: 0.9709\n",
      "comm_round: 11 | global_acc: 92.381% | global_loss: 0.38901010155677795\n",
      "1920\n",
      "comm_round: 11 | global_acc: 95.714% | global_loss: 0.3585195541381836\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0325 - categorical_accuracy: 0.9894\n",
      "comm_round: 12 | global_acc: 95.714% | global_loss: 0.35271066427230835\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0215 - categorical_accuracy: 0.9947\n",
      "comm_round: 12 | global_acc: 96.667% | global_loss: 0.34813088178634644\n",
      "1920\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0286 - categorical_accuracy: 0.9947\n",
      "comm_round: 12 | global_acc: 98.571% | global_loss: 0.33043044805526733\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0300 - categorical_accuracy: 0.9868\n",
      "comm_round: 12 | global_acc: 95.714% | global_loss: 0.3590300679206848\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0273 - categorical_accuracy: 0.9947\n",
      "comm_round: 12 | global_acc: 94.286% | global_loss: 0.36673277616500854\n",
      "1920\n",
      "comm_round: 12 | global_acc: 97.619% | global_loss: 0.33900001645088196\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0129 - categorical_accuracy: 0.9974\n",
      "comm_round: 13 | global_acc: 95.238% | global_loss: 0.3558447062969208\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0124 - categorical_accuracy: 0.9947\n",
      "comm_round: 13 | global_acc: 94.286% | global_loss: 0.3763333857059479\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0567 - categorical_accuracy: 0.9841\n",
      "comm_round: 13 | global_acc: 96.190% | global_loss: 0.35348713397979736\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0590 - categorical_accuracy: 0.9735\n",
      "comm_round: 13 | global_acc: 96.667% | global_loss: 0.34959378838539124\n",
      "1920\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0102 - categorical_accuracy: 1.0000\n",
      "comm_round: 13 | global_acc: 95.714% | global_loss: 0.3579006493091583\n",
      "1920\n",
      "comm_round: 13 | global_acc: 96.190% | global_loss: 0.35283100605010986\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0089 - categorical_accuracy: 0.9947\n",
      "comm_round: 14 | global_acc: 96.190% | global_loss: 0.3475525677204132\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0300 - categorical_accuracy: 0.9921\n",
      "comm_round: 14 | global_acc: 96.190% | global_loss: 0.3480680584907532\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0721 - categorical_accuracy: 0.9788\n",
      "comm_round: 14 | global_acc: 96.190% | global_loss: 0.36091136932373047\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0718 - categorical_accuracy: 0.9762\n",
      "comm_round: 14 | global_acc: 74.762% | global_loss: 0.5423198342323303\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0841 - categorical_accuracy: 0.9735\n",
      "comm_round: 14 | global_acc: 87.143% | global_loss: 0.445681631565094\n",
      "1920\n",
      "comm_round: 14 | global_acc: 93.333% | global_loss: 0.3790815472602844\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0714 - categorical_accuracy: 0.9815\n",
      "comm_round: 15 | global_acc: 91.429% | global_loss: 0.39422810077667236\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0719 - categorical_accuracy: 0.9656\n",
      "comm_round: 15 | global_acc: 81.429% | global_loss: 0.4696162939071655\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0236 - categorical_accuracy: 0.9868\n",
      "comm_round: 15 | global_acc: 82.381% | global_loss: 0.477388858795166\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0478 - categorical_accuracy: 0.9894\n",
      "comm_round: 15 | global_acc: 89.524% | global_loss: 0.4115232825279236\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0109 - categorical_accuracy: 0.9974\n",
      "comm_round: 15 | global_acc: 96.190% | global_loss: 0.3477974534034729\n",
      "1920\n",
      "comm_round: 15 | global_acc: 94.762% | global_loss: 0.36770614981651306\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0325 - categorical_accuracy: 0.9921\n",
      "comm_round: 16 | global_acc: 96.667% | global_loss: 0.34236380457878113\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0363 - categorical_accuracy: 0.9841\n",
      "comm_round: 16 | global_acc: 87.619% | global_loss: 0.427802175283432\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0061 - categorical_accuracy: 1.0000\n",
      "comm_round: 16 | global_acc: 98.571% | global_loss: 0.3292737603187561\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0086 - categorical_accuracy: 0.9974\n",
      "comm_round: 16 | global_acc: 95.714% | global_loss: 0.353845477104187\n",
      "1920\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0459 - categorical_accuracy: 0.9868\n",
      "comm_round: 16 | global_acc: 93.810% | global_loss: 0.3634924292564392\n",
      "1920\n",
      "comm_round: 16 | global_acc: 98.095% | global_loss: 0.32977935671806335\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0925 - categorical_accuracy: 0.9630\n",
      "comm_round: 17 | global_acc: 78.571% | global_loss: 0.5173637866973877\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0883 - categorical_accuracy: 0.9630\n",
      "comm_round: 17 | global_acc: 93.333% | global_loss: 0.3909481167793274\n",
      "1920\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0412 - categorical_accuracy: 0.9815\n",
      "comm_round: 17 | global_acc: 95.714% | global_loss: 0.36736732721328735\n",
      "1920\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0010 - categorical_accuracy: 1.0000\n",
      "comm_round: 17 | global_acc: 96.667% | global_loss: 0.3406960666179657\n",
      "1920\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.5566e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 17 | global_acc: 98.571% | global_loss: 0.32473301887512207\n",
      "1920\n",
      "comm_round: 17 | global_acc: 97.143% | global_loss: 0.3378044366836548\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0010 - categorical_accuracy: 1.0000\n",
      "comm_round: 18 | global_acc: 97.143% | global_loss: 0.3406781256198883\n",
      "1920\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0025 - categorical_accuracy: 1.0000\n",
      "comm_round: 18 | global_acc: 94.762% | global_loss: 0.36520618200302124\n",
      "1920\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0021 - categorical_accuracy: 1.0000\n",
      "comm_round: 18 | global_acc: 97.619% | global_loss: 0.3359021544456482\n",
      "1920\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0064 - categorical_accuracy: 0.9974\n",
      "comm_round: 18 | global_acc: 96.667% | global_loss: 0.34390687942504883\n",
      "1920\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0027 - categorical_accuracy: 1.0000\n",
      "comm_round: 18 | global_acc: 96.190% | global_loss: 0.34537702798843384\n",
      "1920\n",
      "comm_round: 18 | global_acc: 97.619% | global_loss: 0.3355916738510132\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.2688e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 19 | global_acc: 96.667% | global_loss: 0.34877219796180725\n",
      "1920\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.8396e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 19 | global_acc: 97.619% | global_loss: 0.33675357699394226\n",
      "1920\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.7830e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 19 | global_acc: 97.619% | global_loss: 0.3357686698436737\n",
      "1920\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.7338e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 19 | global_acc: 97.619% | global_loss: 0.3357236981391907\n",
      "1920\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4318e-04 - categorical_accuracy: 1.0000\n",
      "comm_round: 19 | global_acc: 97.619% | global_loss: 0.33594682812690735\n",
      "1920\n",
      "comm_round: 19 | global_acc: 97.619% | global_loss: 0.33620500564575195\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "comms_round = 20\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    \n",
    "    \n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    #random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    count = 0\n",
    "    for client in client_names:\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=1)\n",
    "        test_model(X_test, y_test, local_model, comm_round)\n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        \n",
    "        #K.clear_session()\n",
    "        #gc.collect()\n",
    "        #del local_model\n",
    "    \n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predict_x\u001b[38;5;241m=\u001b[39mglobal_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_train\u001b[49m) \n\u001b[0;32m      2\u001b[0m classes_x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(predict_x,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "predict_x=global_model.predict(X_train) \n",
    "classes_x=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in classes_x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
